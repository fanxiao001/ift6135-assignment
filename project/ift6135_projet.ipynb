{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IFT6135 Projet: ICLR2018 Reproducibility Challenge\n",
    "####  Paper: Certifying Some Distributional Robustness With Principled Adversarial Training\n",
    "\n",
    "Names: Xiao Fan (20086722) ,  Zhibin Lu (20091078)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/louis/Google Drive/M.Sc-DIRO-UdeM/IFT6135-Apprentissage de repreﾌ《entations/projet\n",
      "/Users/louis/Google Drive/M.Sc-DIRO-UdeM/IFT6135-Apprentissage de repreﾌ《entations/projet\n",
      "/Users/louis/Google Drive/M.Sc-DIRO-UdeM/IFT6135-Apprentissage de repreﾌ《entations/projet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import importlib\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "import torch.utils.data.sampler as sampler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# path = 'C:/Users/lingyu.yue/Documents/Xiao_Fan/GAN'\n",
    "path=\"/Users/louis/Google Drive/M.Sc-DIRO-UdeM/IFT6135-Apprentissage de repreﾌ《entations/projet/\"\n",
    "if os.path.isdir(path):\n",
    "    os.chdir(path)\n",
    "else:\n",
    "    os.chdir(\"./\")\n",
    "print(os.getcwd())\n",
    "\n",
    "import exp1\n",
    "import mnist\n",
    "importlib.reload(exp1)\n",
    "importlib.reload(mnist)\n",
    "USE_CUDA=torch.cuda.is_available()\n",
    "exp1.init_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MNIST data, total 70000\n"
     ]
    }
   ],
   "source": [
    "NO_CLASSES = 10\n",
    "TRAIN_DATA_SIZE = 50000\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "mnist_transforms = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, transform=mnist_transforms, download=True)\n",
    "mnist_test = torchvision.datasets.MNIST(root='./data', train=False, transform=mnist_transforms, download=True)\n",
    "indices = list(range(len(mnist_train)))\n",
    "np.random.shuffle(indices)\n",
    "train_idx, valid_idx = indices[:TRAIN_DATA_SIZE], indices[TRAIN_DATA_SIZE:]\n",
    "train_sampler = sampler.SubsetRandomSampler(train_idx)\n",
    "valid_sampler = sampler.SubsetRandomSampler(valid_idx)\n",
    "train_data_loader = torch.utils.data.DataLoader(\n",
    "    mnist_train, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=10)\n",
    "valid_data_loader = torch.utils.data.DataLoader(\n",
    "    mnist_train, batch_size=BATCH_SIZE,  sampler=valid_sampler, num_workers=10)\n",
    "test_data_loader = torch.utils.data.DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=True, num_workers=10)\n",
    "print('Loaded MNIST data, total',len(mnist_train)+len(mnist_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(exp1)\n",
    "importlib.reload(mnist)\n",
    "\n",
    "filename='mnist_wrm_elu_ep42'\n",
    "mnist_WRM=Mnist_Estimateur(activation='elu')\n",
    "mnist_WRM,_=exp1.loadCheckpoint(mnist_WRM,filename)\n",
    "# print('Accuracy on test data: ',exp1.evaluate(mnist_WRM,test_data_loader))\n",
    "mnist_test = torchvision.datasets.MNIST(root='./data', train=False, transform=mnist_transforms, download=True)\n",
    "\n",
    "indices = list(range(len(5)))\n",
    "np.random.shuffle(indices)\n",
    "samples_data=\n",
    "\n",
    "\n",
    "train_idx, valid_idx = indices[:TRAIN_DATA_SIZE], indices[TRAIN_DATA_SIZE:]\n",
    "train_sampler = sampler.SubsetRandomSampler(train_idx)\n",
    "valid_sampler = sampler.SubsetRandomSampler(valid_idx)\n",
    "test_data_loader = torch.utils.data.DataLoader(mnist_test, batch_size=BATCH_SIZE, shuffle=True, num_workers=10)\n",
    "\n",
    "if cuda_available:\n",
    "    minibatch_noise = minibatch_noise.cuda()\n",
    "\n",
    "fakes = generator(minibatch_noise)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "idx = 1\n",
    "for ind, fake in enumerate(fakes):\n",
    "    fig.add_subplot(4, 4, ind + 1)\n",
    "    plt.imshow(fake.data.cpu().numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
